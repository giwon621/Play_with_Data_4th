{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'watermark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1cfa3c265f7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'load_ext'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'watermark'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'watermark'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-v -p numpy,scipy,sklearn,pandas,matplotlib'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2129\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2130\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2131\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2132\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-66>\u001b[0m in \u001b[0;36mload_ext\u001b[1;34m(self, module_str)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\extension.py\u001b[0m in \u001b[0;36mload_ext\u001b[1;34m(self, module_str)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodule_str\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mUsageError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Missing module name.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextension_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_extension\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'already loaded'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\extensions.py\u001b[0m in \u001b[0;36mload_extension\u001b[1;34m(self, module_str)\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmodule_str\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mprepended_to_syspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m                     \u001b[0mmod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                         print((\"Loading extensions from {dir} is deprecated. \"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'watermark'"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -p numpy,scipy,sklearn,pandas,matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3장 – 분류**\n",
    "\n",
    "_이 노트북은 3장에 있는 모든 샘플 코드와 연습문제 해답을 가지고 있습니다._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이썬 2와 3을 모두 지원합니다. 공통 모듈을 임포트하고 맷플롯립 그림이 노트북 안에 포함되도록 설정하고 생성한 그림을 저장하기 위한 함수를 준비합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬 2와 파이썬 3 지원\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# 공통\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 일관된 출력을 위해 유사난수 초기화\n",
    "np.random.seed(42)\n",
    "\n",
    "# 맷플롯립 설정\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# 한글출력\n",
    "matplotlib.rc('font', family='NanumBarunGothic')\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 그림을 저장할 폴드\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"classification\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 연습문제 해답"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 97% 정확도의 MNIST 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KNeighborsClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-92a4f0e13b1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'weights'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"uniform\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"distance\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'n_neighbors'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mknn_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknn_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KNeighborsClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [{'weights': [\"uniform\", \"distance\"], 'n_neighbors': [3, 4, 5]}]\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "grid_search = GridSearchCV(knn_clf, param_grid, cv=5, verbose=3, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 4, 'weights': 'distance'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97325"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9714"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 증식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_image(image, dx, dy):\n",
    "    image = image.reshape((28, 28))\n",
    "    shifted_image = shift(image, [dy, dx], cval=0, mode=\"constant\")\n",
    "    return shifted_image.reshape([-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = X_train[1000]\n",
    "shifted_image_down = shift_image(image, 0, 5)\n",
    "shifted_image_left = shift_image(image, -5, 0)\n",
    "\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.subplot(131)\n",
    "plt.title(\"Original\", fontsize=14)\n",
    "plt.imshow(image.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
    "plt.subplot(132)\n",
    "plt.title(\"Shifted down\", fontsize=14)\n",
    "plt.imshow(shifted_image_down.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
    "plt.subplot(133)\n",
    "plt.title(\"Shifted left\", fontsize=14)\n",
    "plt.imshow(shifted_image_left.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_augmented = [image for image in X_train]\n",
    "y_train_augmented = [label for label in y_train]\n",
    "\n",
    "for dx, dy in ((1, 0), (-1, 0), (0, 1), (0, -1)):\n",
    "    for image, label in zip(X_train, y_train):\n",
    "        X_train_augmented.append(shift_image(image, dx, dy))\n",
    "        y_train_augmented.append(label)\n",
    "\n",
    "X_train_augmented = np.array(X_train_augmented)\n",
    "y_train_augmented = np.array(y_train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_idx = np.random.permutation(len(X_train_augmented))\n",
    "X_train_augmented = X_train_augmented[shuffle_idx]\n",
    "y_train_augmented = y_train_augmented[shuffle_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier(**grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=4, p=2,\n",
       "           weights='distance')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf.fit(X_train_augmented, y_train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9763"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = knn_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "간단한 데이터 증식으로 0.5%의 정확도가 향상되었습니다. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 타이타닉 데이터셋에 도전"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "승객의 나이, 성별, 승객 등급, 승선 위치 같은 속성을 기반으로 하여 승객의 생존 여부를 예측하는 것이 목표입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 [캐글](https://www.kaggle.com)에 로그인 하고 [타이타닉 챌린지](https://www.kaggle.com/c/titanic)에서 `train.csv`와 `test.csv`를 다운로드합니다. 두 파일을 `datasets/titanic` 디렉토리에 저장하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그다음 데이터를 적재합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "TITANIC_PATH = os.path.join(\"datasets\", \"titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_titanic_data(filename, titanic_path=TITANIC_PATH):\n",
    "    csv_path = os.path.join(titanic_path, filename)\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_titanic_data(\"train.csv\")\n",
    "test_data = load_titanic_data(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터는 이미 훈련 세트와 테스트 세트로 분리되어 있습니다. 그러나 테스트 데이터는 레이블을 가지고 있지 않습니다: 훈련 데이터를 이용하여 가능한 최고의 모델을 만들고 테스트 데이터에 대한 예측을 캐글(Kaggle)에 업로드하여 최종 점수를 확인하는 것이 목표입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 세트에서 맨 위 몇 개의 열을 살펴 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "속성은 다음과 같은 의미를 가집니다:\n",
    "* **Survived**: 타깃입니다. 0은 생존하지 못한 것이고 1은 생존을 의미합니다.\n",
    "* **Pclass**: 승객 등급. 1, 2, 3등석.\n",
    "* **Name**, **Sex**, **Age**: 이름 그대로 의미입니다.\n",
    "* **SibSp**: 함께 탑승한 형제, 배우자의 수.\n",
    "* **Parch**: 함께 탑승한 자녀, 부모의 수.\n",
    "* **Ticket**: 티켓 아이디\n",
    "* **Fare**: 티켓 요금 (파운드)\n",
    "* **Cabin**: 객실 번호\n",
    "* **Embarked**: 승객이 탑승한 곳. C(Cherbourg), Q(Queenstown), S(Southampton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "누락된 데이터가 얼마나 되는지 알아보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "괜찮네요. **Age**, **Cabin**, **Embarked** 속성의 일부가 null입니다(891개의 non-null 보다 작습니다). 특히 **Cabin**은 77%가 null입니다. 일단 **Cabin**은 무시하고 나머지를 활용하겠습니다. **Age**는 19%가 null이므로 이를 어떻게 처리할지 결정해야 합니다. null을 중간 나이로 바꾸는 것이 괜찮아 보입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name**과 **Ticket** 속성도 값을 가지고 있지만 머신러닝 모델이 사용할 수 있는 숫자로 변환하는 것이 조금 까다롭습니다. 그래서 지금은 이 두 속성을 무시하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "통계치를 살펴 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 이크, 38%만 **Survived**입니다. :( 거의 40%에 가까우므로 정확도를 사용해 모델을 평가해도 괜찮을 것 같습니다.\n",
    "* 평균 **Fare**는 32.20 파운드라 그렇게 비싸보이지는 않습니다(아마 요금을 많이 반환해 주었기 때문일 것입니다)\n",
    "* 평균 **Age**는 30보다 작습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타깃이 0과 1로 이루어졌는지 확인합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Survived\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "범주형 특성들을 확인해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    491\n",
       "1    216\n",
       "2    184\n",
       "Name: Pclass, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Pclass\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      577\n",
       "female    314\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Embarked\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embarked** 특성은 승객이 탑승한 곳을 알려 줍니다: C=Cherbourg, Q=Queenstown, S=Southampton."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CategoricalEncoder` 클래스는 범주형 특성을 원-핫 벡터로 변환시켜 줍니다. 이 클래스는 사이킷런 0.20에 포함될 예정이지만 지금은 아래 코드를 사용합니다([#9151](https://github.com/scikit-learn/scikit-learn/pull/9151) 풀 리퀘스트에서 복사했습니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PR #9151에서 가져온 CategoricalEncoder 클래스의 정의.\n",
    "# 이 클래스는 사이킷런 0.20에 포함될 예정입니다.\n",
    "# 이 셀을 실행하거나 복사해서 사용하세요. 이 코드를 모두 이해할 필요는 없습니다.\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy import sparse\n",
    "\n",
    "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Encode categorical features as a numeric array.\n",
    "    The input to this transformer should be a matrix of integers or strings,\n",
    "    denoting the values taken on by categorical (discrete) features.\n",
    "    The features can be encoded using a one-hot aka one-of-K scheme\n",
    "    (``encoding='onehot'``, the default) or converted to ordinal integers\n",
    "    (``encoding='ordinal'``).\n",
    "    This encoding is needed for feeding categorical data to many scikit-learn\n",
    "    estimators, notably linear models and SVMs with the standard kernels.\n",
    "    Read more in the :ref:`User Guide <preprocessing_categorical_features>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    encoding : str, 'onehot', 'onehot-dense' or 'ordinal'\n",
    "        The type of encoding to use (default is 'onehot'):\n",
    "        - 'onehot': encode the features using a one-hot aka one-of-K scheme\n",
    "          (or also called 'dummy' encoding). This creates a binary column for\n",
    "          each category and returns a sparse matrix.\n",
    "        - 'onehot-dense': the same as 'onehot' but returns a dense array\n",
    "          instead of a sparse matrix.\n",
    "        - 'ordinal': encode the features as ordinal integers. This results in\n",
    "          a single column of integers (0 to n_categories - 1) per feature.\n",
    "    categories : 'auto' or a list of lists/arrays of values.\n",
    "        Categories (unique values) per feature:\n",
    "        - 'auto' : Determine categories automatically from the training data.\n",
    "        - list : ``categories[i]`` holds the categories expected in the ith\n",
    "          column. The passed categories are sorted before encoding the data\n",
    "          (used categories can be found in the ``categories_`` attribute).\n",
    "    dtype : number type, default np.float64\n",
    "        Desired dtype of output.\n",
    "    handle_unknown : 'error' (default) or 'ignore'\n",
    "        Whether to raise an error or ignore if a unknown categorical feature is\n",
    "        present during transform (default is to raise). When this is parameter\n",
    "        is set to 'ignore' and an unknown category is encountered during\n",
    "        transform, the resulting one-hot encoded columns for this feature\n",
    "        will be all zeros.\n",
    "        Ignoring unknown categories is not supported for\n",
    "        ``encoding='ordinal'``.\n",
    "    Attributes\n",
    "    ----------\n",
    "    categories_ : list of arrays\n",
    "        The categories of each feature determined during fitting. When\n",
    "        categories were specified manually, this holds the sorted categories\n",
    "        (in order corresponding with output of `transform`).\n",
    "    Examples\n",
    "    --------\n",
    "    Given a dataset with three features and two samples, we let the encoder\n",
    "    find the maximum value per feature and transform the data to a binary\n",
    "    one-hot encoding.\n",
    "    >>> from sklearn.preprocessing import CategoricalEncoder\n",
    "    >>> enc = CategoricalEncoder(handle_unknown='ignore')\n",
    "    >>> enc.fit([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]])\n",
    "    ... # doctest: +ELLIPSIS\n",
    "    CategoricalEncoder(categories='auto', dtype=<... 'numpy.float64'>,\n",
    "              encoding='onehot', handle_unknown='ignore')\n",
    "    >>> enc.transform([[0, 1, 1], [1, 0, 4]]).toarray()\n",
    "    array([[ 1.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.],\n",
    "           [ 0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
    "    See also\n",
    "    --------\n",
    "    sklearn.preprocessing.OneHotEncoder : performs a one-hot encoding of\n",
    "      integer ordinal features. The ``OneHotEncoder assumes`` that input\n",
    "      features take on values in the range ``[0, max(feature)]`` instead of\n",
    "      using the unique values.\n",
    "    sklearn.feature_extraction.DictVectorizer : performs a one-hot encoding of\n",
    "      dictionary items (also handles string-valued features).\n",
    "    sklearn.feature_extraction.FeatureHasher : performs an approximate one-hot\n",
    "      encoding of dictionary items or strings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoding='onehot', categories='auto', dtype=np.float64,\n",
    "                 handle_unknown='error'):\n",
    "        self.encoding = encoding\n",
    "        self.categories = categories\n",
    "        self.dtype = dtype\n",
    "        self.handle_unknown = handle_unknown\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fit the CategoricalEncoder to X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape [n_samples, n_feature]\n",
    "            The data to determine the categories of each feature.\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "\n",
    "        if self.encoding not in ['onehot', 'onehot-dense', 'ordinal']:\n",
    "            template = (\"encoding should be either 'onehot', 'onehot-dense' \"\n",
    "                        \"or 'ordinal', got %s\")\n",
    "            raise ValueError(template % self.handle_unknown)\n",
    "\n",
    "        if self.handle_unknown not in ['error', 'ignore']:\n",
    "            template = (\"handle_unknown should be either 'error' or \"\n",
    "                        \"'ignore', got %s\")\n",
    "            raise ValueError(template % self.handle_unknown)\n",
    "\n",
    "        if self.encoding == 'ordinal' and self.handle_unknown == 'ignore':\n",
    "            raise ValueError(\"handle_unknown='ignore' is not supported for\"\n",
    "                             \" encoding='ordinal'\")\n",
    "\n",
    "        X = check_array(X, dtype=np.object, accept_sparse='csc', copy=True)\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        self._label_encoders_ = [LabelEncoder() for _ in range(n_features)]\n",
    "\n",
    "        for i in range(n_features):\n",
    "            le = self._label_encoders_[i]\n",
    "            Xi = X[:, i]\n",
    "            if self.categories == 'auto':\n",
    "                le.fit(Xi)\n",
    "            else:\n",
    "                valid_mask = np.in1d(Xi, self.categories[i])\n",
    "                if not np.all(valid_mask):\n",
    "                    if self.handle_unknown == 'error':\n",
    "                        diff = np.unique(Xi[~valid_mask])\n",
    "                        msg = (\"Found unknown categories {0} in column {1}\"\n",
    "                               \" during fit\".format(diff, i))\n",
    "                        raise ValueError(msg)\n",
    "                le.classes_ = np.array(np.sort(self.categories[i]))\n",
    "\n",
    "        self.categories_ = [le.classes_ for le in self._label_encoders_]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform X using one-hot encoding.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape [n_samples, n_features]\n",
    "            The data to encode.\n",
    "        Returns\n",
    "        -------\n",
    "        X_out : sparse matrix or a 2-d array\n",
    "            Transformed input.\n",
    "        \"\"\"\n",
    "        X = check_array(X, accept_sparse='csc', dtype=np.object, copy=True)\n",
    "        n_samples, n_features = X.shape\n",
    "        X_int = np.zeros_like(X, dtype=np.int)\n",
    "        X_mask = np.ones_like(X, dtype=np.bool)\n",
    "\n",
    "        for i in range(n_features):\n",
    "            valid_mask = np.in1d(X[:, i], self.categories_[i])\n",
    "\n",
    "            if not np.all(valid_mask):\n",
    "                if self.handle_unknown == 'error':\n",
    "                    diff = np.unique(X[~valid_mask, i])\n",
    "                    msg = (\"Found unknown categories {0} in column {1}\"\n",
    "                           \" during transform\".format(diff, i))\n",
    "                    raise ValueError(msg)\n",
    "                else:\n",
    "                    # Set the problematic rows to an acceptable value and\n",
    "                    # continue `The rows are marked `X_mask` and will be\n",
    "                    # removed later.\n",
    "                    X_mask[:, i] = valid_mask\n",
    "                    X[:, i][~valid_mask] = self.categories_[i][0]\n",
    "            X_int[:, i] = self._label_encoders_[i].transform(X[:, i])\n",
    "\n",
    "        if self.encoding == 'ordinal':\n",
    "            return X_int.astype(self.dtype, copy=False)\n",
    "\n",
    "        mask = X_mask.ravel()\n",
    "        n_values = [cats.shape[0] for cats in self.categories_]\n",
    "        n_values = np.array([0] + n_values)\n",
    "        indices = np.cumsum(n_values)\n",
    "\n",
    "        column_indices = (X_int + indices[:-1]).ravel()[mask]\n",
    "        row_indices = np.repeat(np.arange(n_samples, dtype=np.int32),\n",
    "                                n_features)[mask]\n",
    "        data = np.ones(n_samples * n_features)[mask]\n",
    "\n",
    "        out = sparse.csc_matrix((data, (row_indices, column_indices)),\n",
    "                                shape=(n_samples, indices[-1]),\n",
    "                                dtype=self.dtype).tocsr()\n",
    "        if self.encoding == 'onehot-dense':\n",
    "            return out.toarray()\n",
    "        else:\n",
    "            return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 전처리 파이프라인을 만듭니다. `DataFrame`으로부터 특정 속성만 선택하기 위해 이전 장에서 만든 `DataframeSelector`를 재사용하겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# 사이킷런이 DataFrame을 바로 사용하지 못하므로\n",
    "# 수치형이나 범주형 컬럼을 선택하는 클래스를 만듭니다.\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "숫자 특성을 위한 파이프라인을 만듭니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imputer = Imputer(strategy=\"median\")\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        (\"select_numeric\", DataFrameSelector([\"Age\", \"SibSp\", \"Parch\", \"Fare\"])),\n",
    "        (\"imputer\", Imputer(strategy=\"median\")),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.    ,  1.    ,  0.    ,  7.25  ],\n",
       "       [38.    ,  1.    ,  0.    , 71.2833],\n",
       "       [26.    ,  0.    ,  0.    ,  7.925 ],\n",
       "       ...,\n",
       "       [28.    ,  1.    ,  2.    , 23.45  ],\n",
       "       [26.    ,  0.    ,  0.    , 30.    ],\n",
       "       [32.    ,  0.    ,  0.    ,  7.75  ]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pipeline.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문자열로된 범주형 열을 위해 별도의 Imputer 클래스가 필요합니다(일반 `Imputer` 클래스는 이를 처리하지 못합니다):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stackoverflow.com/questions/25239958 에서 착안했습니다\n",
    "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X],\n",
    "                                       index=X.columns)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.most_frequent_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 범주형 특성을 위한 파이프라인을 만듭니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline = Pipeline([\n",
    "        (\"select_cat\", DataFrameSelector([\"Pclass\", \"Sex\", \"Embarked\"])),\n",
    "        (\"imputer\", MostFrequentImputer()),\n",
    "        (\"cat_encoder\", CategoricalEncoder(encoding='onehot-dense')),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### future_encoders.py를 사용한 방법 ==========================\n",
    "\n",
    "주의: 번역서는 `CategoricalEncoder`를 사용하여 각 범주형 값을 원-핫 벡터로 변경합니다. `OneHotEncoder`를 사용하는 것이 더 낫습니다. 지금은 정수형 범주 입력만 다룰 수 있지만 사이킷런 0.20에서는 문자열 범주 입력도 다룰 수 있을 것입니다(PR #10521). 지금은 `future_encoders.py` 파일에서 임포트하지만 사이킷런 0.20 버전이 릴리스되면 `sklearn.preprocessing`에서 바로 임포팅할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from future_encoders import OneHotEncoder\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        (\"select_cat\", DataFrameSelector([\"Pclass\", \"Sex\", \"Embarked\"])),\n",
    "        (\"imputer\", MostFrequentImputer()),\n",
    "        (\"cat_encoder\", OneHotEncoder(sparse=False)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ===================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_pipeline.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로 숫자와 범주형 파이프라인을 연결합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "preprocess_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "좋습니다! 이제 원본 데이터를 받아 머신러닝 모델에 주입할 숫자 입력 특성을 출력하는 전처리 파이프라인을 만들었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.,  1.,  0., ...,  0.,  0.,  1.],\n",
       "       [38.,  1.,  0., ...,  1.,  0.,  0.],\n",
       "       [26.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       ...,\n",
       "       [28.,  1.,  2., ...,  0.,  0.,  1.],\n",
       "       [26.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [32.,  0.,  0., ...,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = preprocess_pipeline.fit_transform(train_data)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이블을 가져옵니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data[\"Survived\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 분류기를 훈련시킬 차례입니다. 먼저 `SVC`를 사용해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC()\n",
    "svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델이 잘 훈련된 것 같습니다. 이를 사용해서 테스트 세트에 대한 예측을 만듭니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = preprocess_pipeline.transform(test_data)\n",
    "y_pred = svm_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 예측 결과를 (캐글에서 기대하는 형태인) CSV 파일로 만들어 업로드하고 평가를 받아볼 수 있습니다. 하지만 그냥 좋을거라 기대하는 것보다 교차 검증으로 모델이 얼마나 좋은지 평가하는 것이 좋습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7365250822835092"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "svm_scores = cross_val_score(svm_clf, X_train, y_train, cv=10)\n",
    "svm_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확도가 73% 이상입니다. 확실히 무작위로 선택한 것보다는 좋습니다. 하지만 아주 높은 점수는 아닙니다. 캐글에서 타이타닉 경연 대회의 [리더보드](https://www.kaggle.com/c/titanic/leaderboard)를 보면 상위 10%내에 들려면 80% 이상의 정확도를 내야합니다. 어떤 사람들은 100%를 달성했습니다. 하지만 타이타닉의 [희생자 목록](https://www.encyclopedia-titanica.org/titanic-victims/)을 쉽게 찾을 수 있으므로 머신러닝을 사용하지 않고도 이런 정확도를 달성할 수 있습니다! ;-) 우리는 80% 정도의 정확도를 내는 모델을 만들어 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RandomForestClassifier`를 적용해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8115690614005221"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "forest_scores = cross_val_score(forest_clf, X_train, y_train, cv=10)\n",
    "forest_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훨씬 좋네요!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 폴드 교차 검증에 대한 평균 정확도를 보는 대신 모델에서 얻은 10개의 점수를 1사분위, 3사분위를 명료하게 표현해주는 상자 수염 그림(box-and-whisker) 그래프를 만들어 보겠습니다(이 방식을 제안해 준 Nevin Yilmaz에게 감사합니다). `boxplot()` 함수는 이상치(플라이어(flier)라고 부릅니다)를 감지하고 수염 부분에 이를 포함시키지 않습니다. 1사분위가 $Q_1$이고 3사분위가 $Q_3$이라면 사분위수 범위는 $IQR = Q_3 - Q_1$가 됩니다(이 값이 박스의 높이가 됩니다). $Q_1 - 1.5 \\times IQR$ 보다 낮거나 $Q3 + 1.5 \\times IQR$ 보다 높은 점수는 이상치로 간주됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot([1]*10, svm_scores, \".\")\n",
    "plt.plot([2]*10, forest_scores, \".\")\n",
    "plt.boxplot([svm_scores, forest_scores], labels=(\"SVM\",\"Random Forest\"))\n",
    "plt.ylabel(\"정확도\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 결과를 더 향상시키려면:\n",
    "* 교차 검증과 그리드 탐색을 사용하여 더 많은 모델을 비교하고 하이퍼파라미터를 튜닝하세요.\n",
    "* 특성 공학을 더 시도해 보세요, 예를 들면:\n",
    "  * **SibSp**와 **Parch**을 이 두 특성의 합으로 바꿉니다.\n",
    "  * **Survived** 특성과 관련된 이름을 구별해 보세요(가령, 이름에 \"Countess\"가 있는 경우 생존할 가능성이 높습니다).\n",
    "* 수치 특성을 범주형 특성으로 바꾸어 보세요: 예를 들어, 나이대가 다른 경우 다른 생존 비율을 가질 수 있습니다(아래 참조). 그러므로 나이 구간을 범주로 만들어 나이 대신 사용하는 것이 도움이 될 수 있스니다. 비슷하게 생존자의 30%가 혼자 여행하는 사람이기 때문에 이들을 위한 특별한 범주를 만드는 것이 도움이 될 수 있습니다(아래 참조)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgeBucket</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.576923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>0.362745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30.0</th>\n",
       "      <td>0.423256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45.0</th>\n",
       "      <td>0.404494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60.0</th>\n",
       "      <td>0.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75.0</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Survived\n",
       "AgeBucket          \n",
       "0.0        0.576923\n",
       "15.0       0.362745\n",
       "30.0       0.423256\n",
       "45.0       0.404494\n",
       "60.0       0.240000\n",
       "75.0       1.000000"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"AgeBucket\"] = train_data[\"Age\"] // 15 * 15\n",
    "train_data[[\"AgeBucket\", \"Survived\"]].groupby(['AgeBucket']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RelativesOnboard</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.303538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.552795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.578431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.724138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Survived\n",
       "RelativesOnboard          \n",
       "0                 0.303538\n",
       "1                 0.552795\n",
       "2                 0.578431\n",
       "3                 0.724138\n",
       "4                 0.200000\n",
       "5                 0.136364\n",
       "6                 0.333333\n",
       "7                 0.000000\n",
       "10                0.000000"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"RelativesOnboard\"] = train_data[\"SibSp\"] + train_data[\"Parch\"]\n",
    "train_data[[\"RelativesOnboard\", \"Survived\"]].groupby(['RelativesOnboard']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 스팸 필터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 데이터를 다운받습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "\n",
    "DOWNLOAD_ROOT = \"http://spamassassin.apache.org/old/publiccorpus/\"\n",
    "HAM_URL = DOWNLOAD_ROOT + \"20030228_easy_ham.tar.bz2\"\n",
    "SPAM_URL = DOWNLOAD_ROOT + \"20030228_spam.tar.bz2\"\n",
    "SPAM_PATH = os.path.join(\"datasets\", \"spam\")\n",
    "\n",
    "def fetch_spam_data(spam_url=SPAM_URL, spam_path=SPAM_PATH):\n",
    "    if not os.path.isdir(spam_path):\n",
    "        os.makedirs(spam_path)\n",
    "    for filename, url in ((\"ham.tar.bz2\", HAM_URL), (\"spam.tar.bz2\", SPAM_URL)):\n",
    "        path = os.path.join(spam_path, filename)\n",
    "        if not os.path.isfile(path):\n",
    "            urllib.request.urlretrieve(url, path)\n",
    "        tar_bz2_file = tarfile.open(path)\n",
    "        tar_bz2_file.extractall(path=SPAM_PATH)\n",
    "        tar_bz2_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_spam_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음, 모든 이메일을 읽어 들입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAM_DIR = os.path.join(SPAM_PATH, \"easy_ham\")\n",
    "SPAM_DIR = os.path.join(SPAM_PATH, \"spam\")\n",
    "ham_filenames = [name for name in sorted(os.listdir(HAM_DIR)) if len(name) > 20]\n",
    "spam_filenames = [name for name in sorted(os.listdir(SPAM_DIR)) if len(name) > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ham_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spam_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이썬의 `email` 모듈을 사용해 이메일을 파싱합니다(헤더, 인코딩 등을 처리합니다):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "import email.policy\n",
    "\n",
    "def load_email(is_spam, filename, spam_path=SPAM_PATH):\n",
    "    directory = \"spam\" if is_spam else \"easy_ham\"\n",
    "    with open(os.path.join(spam_path, directory, filename), \"rb\") as f:\n",
    "        return email.parser.BytesParser(policy=email.policy.default).parse(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_emails = [load_email(is_spam=False, filename=name) for name in ham_filenames]\n",
    "spam_emails = [load_email(is_spam=True, filename=name) for name in spam_filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터가 어떻게 구성되어 있는지 감을 잡기 위해 햄 메일과 스팸 메일을 하나씩 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Martin A posted:\n",
      "Tassos Papadopoulos, the Greek sculptor behind the plan, judged that the\n",
      " limestone of Mount Kerdylio, 70 miles east of Salonika and not far from the\n",
      " Mount Athos monastic community, was ideal for the patriotic sculpture. \n",
      " \n",
      " As well as Alexander's granite features, 240 ft high and 170 ft wide, a\n",
      " museum, a restored amphitheatre and car park for admiring crowds are\n",
      "planned\n",
      "---------------------\n",
      "So is this mountain limestone or granite?\n",
      "If it's limestone, it'll weather pretty fast.\n",
      "\n",
      "------------------------ Yahoo! Groups Sponsor ---------------------~-->\n",
      "4 DVDs Free +s&p Join Now\n",
      "http://us.click.yahoo.com/pt6YBB/NXiEAA/mG3HAA/7gSolB/TM\n",
      "---------------------------------------------------------------------~->\n",
      "\n",
      "To unsubscribe from this group, send an email to:\n",
      "forteana-unsubscribe@egroups.com\n",
      "\n",
      " \n",
      "\n",
      "Your use of Yahoo! Groups is subject to http://docs.yahoo.com/info/terms/\n"
     ]
    }
   ],
   "source": [
    "print(ham_emails[1].get_content().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help wanted.  We are a 14 year old fortune 500 company, that is\n",
      "growing at a tremendous rate.  We are looking for individuals who\n",
      "want to work from home.\n",
      "\n",
      "This is an opportunity to make an excellent income.  No experience\n",
      "is required.  We will train you.\n",
      "\n",
      "So if you are looking to be employed from home with a career that has\n",
      "vast opportunities, then go:\n",
      "\n",
      "http://www.basetel.com/wealthnow\n",
      "\n",
      "We are looking for energetic and self motivated people.  If that is you\n",
      "than click on the link and fill out the form, and one of our\n",
      "employement specialist will contact you.\n",
      "\n",
      "To be removed from our link simple go to:\n",
      "\n",
      "http://www.basetel.com/remove.html\n",
      "\n",
      "\n",
      "4139vOLW7-758DoDY1425FRhM1-764SMFc8513fCsLl40\n"
     ]
    }
   ],
   "source": [
    "print(spam_emails[6].get_content().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어떤 이메일은 이미지나 첨부 파일을 가진 멀티파트(multipart)입니다(메일에 포함되어 있을수 있습니다). 어떤 파일들이 있는지 살펴 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email_structure(email):\n",
    "    if isinstance(email, str):\n",
    "        return email\n",
    "    payload = email.get_payload()\n",
    "    if isinstance(payload, list):\n",
    "        return \"multipart({})\".format(\", \".join([\n",
    "            get_email_structure(sub_email)\n",
    "            for sub_email in payload\n",
    "        ]))\n",
    "    else:\n",
    "        return email.get_content_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def structures_counter(emails):\n",
    "    structures = Counter()\n",
    "    for email in emails:\n",
    "        structure = get_email_structure(email)\n",
    "        structures[structure] += 1\n",
    "    return structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text/plain', 2408),\n",
       " ('multipart(text/plain, application/pgp-signature)', 66),\n",
       " ('multipart(text/plain, text/html)', 8),\n",
       " ('multipart(text/plain, text/plain)', 4),\n",
       " ('multipart(text/plain)', 3),\n",
       " ('multipart(text/plain, application/octet-stream)', 2),\n",
       " ('multipart(multipart(text/plain, text/plain, text/plain), application/pgp-signature)',\n",
       "  1),\n",
       " ('multipart(text/plain, text/enriched)', 1),\n",
       " ('multipart(text/plain, video/mng)', 1),\n",
       " ('multipart(text/plain, multipart(text/plain))', 1),\n",
       " ('multipart(text/plain, application/x-java-applet)', 1),\n",
       " ('multipart(text/plain, application/ms-tnef, text/plain)', 1),\n",
       " ('multipart(text/plain, multipart(text/plain, text/plain), multipart(multipart(text/plain, application/x-pkcs7-signature)))',\n",
       "  1),\n",
       " ('multipart(text/plain, application/x-pkcs7-signature)', 1),\n",
       " ('multipart(text/plain, multipart(text/plain, text/plain), text/rfc822-headers)',\n",
       "  1)]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structures_counter(ham_emails).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text/plain', 218),\n",
       " ('text/html', 183),\n",
       " ('multipart(text/plain, text/html)', 45),\n",
       " ('multipart(text/html)', 20),\n",
       " ('multipart(text/plain)', 19),\n",
       " ('multipart(multipart(text/html))', 5),\n",
       " ('multipart(text/plain, image/jpeg)', 3),\n",
       " ('multipart(text/html, application/octet-stream)', 2),\n",
       " ('multipart(multipart(text/html), application/octet-stream, image/jpeg)', 1),\n",
       " ('multipart(multipart(text/plain, text/html), image/gif)', 1),\n",
       " ('multipart(text/plain, application/octet-stream)', 1),\n",
       " ('multipart(text/html, text/plain)', 1),\n",
       " ('multipart/alternative', 1)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structures_counter(spam_emails).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "햄 메일은 평범한 텍스트가 많고 스팸은 HTML일 경우가 많습니다. 적은 수의 햄 이메일이 PGP로 서명되어 있지만 스팸 메일에는 없습니다. 요약하면 이메일 구조는 유용한 정보입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 이메일 헤더를 살펴보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return-Path : <12a1mailbot1@web.de>\n",
      "Delivered-To : zzzz@localhost.spamassassin.taint.org\n",
      "Received : from localhost (localhost [127.0.0.1])\tby phobos.labs.spamassassin.taint.org (Postfix) with ESMTP id 136B943C32\tfor <zzzz@localhost>; Thu, 22 Aug 2002 08:17:21 -0400 (EDT)\n",
      "Received : from mail.webnote.net [193.120.211.219]\tby localhost with POP3 (fetchmail-5.9.0)\tfor zzzz@localhost (single-drop); Thu, 22 Aug 2002 13:17:21 +0100 (IST)\n",
      "Received : from dd_it7 ([210.97.77.167])\tby webnote.net (8.9.3/8.9.3) with ESMTP id NAA04623\tfor <zzzz@spamassassin.taint.org>; Thu, 22 Aug 2002 13:09:41 +0100\n",
      "From : 12a1mailbot1@web.de\n",
      "Received : from r-smtp.korea.com - 203.122.2.197 by dd_it7  with Microsoft SMTPSVC(5.5.1775.675.6);\t Sat, 24 Aug 2002 09:42:10 +0900\n",
      "To : dcek1a1@netsgo.com\n",
      "Subject : Life Insurance - Why Pay More?\n",
      "Date : Wed, 21 Aug 2002 20:31:57 -1600\n",
      "MIME-Version : 1.0\n",
      "Message-ID : <0103c1042001882DD_IT7@dd_it7>\n",
      "Content-Type : text/html; charset=\"iso-8859-1\"\n",
      "Content-Transfer-Encoding : quoted-printable\n"
     ]
    }
   ],
   "source": [
    "for header, value in spam_emails[0].items():\n",
    "    print(header,\":\",value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보낸사람의 이메일 주소와 같이 헤더에는 유용한 정보가 많이 있지만 여기서는 `Subject` 헤더만 다뤄 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Life Insurance - Why Pay More?'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_emails[0][\"Subject\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "좋습니다. 데이터에를 더 살펴보기 전에 훈련 세트와 테스트 세트로 나누도록 하겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(ham_emails + spam_emails)\n",
    "y = np.array([0] * len(ham_emails) + [1] * len(spam_emails))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 전처리 함수를 작성하겠습니다. 먼저 HTML을 일반 텍스트로 변환하는 함수가 필요합니다. 이 작업에는 당연히 [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/) 라이브러리를 사용하는게 좋지만 의존성을 줄이기 위해서 정규식을 사용하여 대강 만들어 보겠습니다([un̨ho͞ly radiańcé destro҉ying all enli̍̈́̂̈́ghtenment](https://stackoverflow.com/a/1732454/38626)의 위험에도 불구하고). 다음 함수는 `<head>` 섹션을 삭제하고 모든 `<a>` 태그를 HYPERLINK 문자로 바꿉니다. 그런 다음 모든 HTML 태그를 제거하고 텍스트만 남깁니다. 보기 편하게 여러개의 개행 문자를 하나로 만들고 (`&gt;`나 `&nbsp;` 같은) html 엔티티를 복원합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from html import unescape\n",
    "\n",
    "def html_to_plain_text(html):\n",
    "    text = re.sub('<head.*?>.*?</head>', '', html, flags=re.M | re.S | re.I)\n",
    "    text = re.sub('<a\\s.*?>', ' HYPERLINK ', text, flags=re.M | re.S | re.I)\n",
    "    text = re.sub('<.*?>', '', text, flags=re.M | re.S)\n",
    "    text = re.sub(r'(\\s*\\n)+', '\\n', text, flags=re.M | re.S)\n",
    "    return unescape(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "잘 작동하는지 확인해 보겠습니다. 다음은 HTML 스팸입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HTML><HEAD><TITLE></TITLE><META http-equiv=\"Content-Type\" content=\"text/html; charset=windows-1252\"><STYLE>A:link {TEX-DECORATION: none}A:active {TEXT-DECORATION: none}A:visited {TEXT-DECORATION: none}A:hover {COLOR: #0033ff; TEXT-DECORATION: underline}</STYLE><META content=\"MSHTML 6.00.2713.1100\" name=\"GENERATOR\"></HEAD>\n",
      "<BODY text=\"#000000\" vLink=\"#0033ff\" link=\"#0033ff\" bgColor=\"#CCCC99\"><TABLE borderColor=\"#660000\" cellSpacing=\"0\" cellPadding=\"0\" border=\"0\" width=\"100%\"><TR><TD bgColor=\"#CCCC99\" valign=\"top\" colspan=\"2\" height=\"27\">\n",
      "<font size=\"6\" face=\"Arial, Helvetica, sans-serif\" color=\"#660000\">\n",
      "<b>OTC</b></font></TD></TR><TR><TD height=\"2\" bgcolor=\"#6a694f\">\n",
      "<font size=\"5\" face=\"Times New Roman, Times, serif\" color=\"#FFFFFF\">\n",
      "<b>&nbsp;Newsletter</b></font></TD><TD height=\"2\" bgcolor=\"#6a694f\"><div align=\"right\"><font color=\"#FFFFFF\">\n",
      "<b>Discover Tomorrow's Winners&nbsp;</b></font></div></TD></TR><TR><TD height=\"25\" colspan=\"2\" bgcolor=\"#CCCC99\"><table width=\"100%\" border=\"0\"  ...\n"
     ]
    }
   ],
   "source": [
    "html_spam_emails = [email for email in X_train[y_train==1]\n",
    "                    if get_email_structure(email) == \"text/html\"]\n",
    "sample_html_spam = html_spam_emails[7]\n",
    "print(sample_html_spam.get_content().strip()[:1000], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "변환된 텍스트입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OTC\n",
      " Newsletter\n",
      "Discover Tomorrow's Winners \n",
      "For Immediate Release\n",
      "Cal-Bay (Stock Symbol: CBYI)\n",
      "Watch for analyst \"Strong Buy Recommendations\" and several advisory newsletters picking CBYI.  CBYI has filed to be traded on the OTCBB, share prices historically INCREASE when companies get listed on this larger trading exchange. CBYI is trading around 25 cents and should skyrocket to $2.66 - $3.25 a share in the near future.\n",
      "Put CBYI on your watch list, acquire a position TODAY.\n",
      "REASONS TO INVEST IN CBYI\n",
      "A profitable company and is on track to beat ALL earnings estimates!\n",
      "One of the FASTEST growing distributors in environmental & safety equipment instruments.\n",
      "Excellent management team, several EXCLUSIVE contracts.  IMPRESSIVE client list including the U.S. Air Force, Anheuser-Busch, Chevron Refining and Mitsubishi Heavy Industries, GE-Energy & Environmental Research.\n",
      "RAPIDLY GROWING INDUSTRY\n",
      "Industry revenues exceed $900 million, estimates indicate that there could be as much as $25 billi ...\n"
     ]
    }
   ],
   "source": [
    "print(html_to_plain_text(sample_html_spam.get_content())[:1000], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아주 좋습니다! 이제 포맷에 상관없이 이메일을 입력으로 받아서 일반 텍스트를 출력하는 함수를 만들겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_to_text(email):\n",
    "    html = None\n",
    "    for part in email.walk():\n",
    "        ctype = part.get_content_type()\n",
    "        if not ctype in (\"text/plain\", \"text/html\"):\n",
    "            continue\n",
    "        try:\n",
    "            content = part.get_content()\n",
    "        except: # in case of encoding issues\n",
    "            content = str(part.get_payload())\n",
    "        if ctype == \"text/plain\":\n",
    "            return content\n",
    "        else:\n",
    "            html = content\n",
    "    if html:\n",
    "        return html_to_plain_text(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OTC\n",
      " Newsletter\n",
      "Discover Tomorrow's Winners \n",
      "For Immediate Release\n",
      "Cal-Bay (Stock Symbol: CBYI)\n",
      "Wat ...\n"
     ]
    }
   ],
   "source": [
    "print(email_to_text(sample_html_spam)[:100], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어간 추출을 해보죠! 이 작업을 하려면 자연어 처리 툴킷([NLTK](http://www.nltk.org/))을 설치해야 합니다. 다음 명령으로 간단히 설치할 수 있습니다(먼저 virtualenv 환경을 활성화시켜야 합니다. 별도의 환경이 없다면 어드민 권한이 필요할지 모릅니다. 아니면 `--user` 옵션을 사용하세요):\n",
    "\n",
    "`$ pip install nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computations => comput\n",
      "Computation => comput\n",
      "Computing => comput\n",
      "Computed => comput\n",
      "Compute => comput\n",
      "Compulsive => compuls\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import nltk\n",
    "\n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    for word in (\"Computations\", \"Computation\", \"Computing\", \"Computed\", \"Compute\", \"Compulsive\"):\n",
    "        print(word, \"=>\", stemmer.stem(word))\n",
    "except ImportError:\n",
    "    print(\"Error: stemming requires the NLTK module.\")\n",
    "    stemmer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인터넷 주소는 \"URL\" 문자로 바꾸겠습니다. [정규식](https://mathiasbynens.be/demo/url-regex)을 하드 코딩할 수도 있지만 [urlextract](https://github.com/lipoja/URLExtract) 라이브러리를 사용하겠습니다. 다음 명령으로 설치합니다(먼저 virtualenv 환경을 활성화시켜야 합니다. 별도의 환경이 없다면 어드민 권한이 필요할지 모릅니다. 아니면 `--user` 옵션을 사용하세요):\n",
    "\n",
    "`$ pip install urlextract`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['github.com', 'https://youtu.be/7Pq-S557XQU?t=3m32s']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import urlextract # 루트 도메인 이름을 다운로드하기 위해 인터넷 연결이 필요할지 모릅니다\n",
    "    \n",
    "    url_extractor = urlextract.URLExtract()\n",
    "    print(url_extractor.find_urls(\"Will it detect github.com and https://youtu.be/7Pq-S557XQU?t=3m32s\"))\n",
    "except ImportError:\n",
    "    print(\"Error: replacing URLs requires the urlextract module.\")\n",
    "    url_extractor = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이들을 모두 하나의 변환기로 연결하여 이메일을 단어 카운트로 바꿀 것입니다. 파이썬의 `split()` 메서드를 사용하면 구둣점과 단어 경계를 기준으로 문장을 단어로 바꿉니다. 이 방법이 많은 언어에 통하지만 전부는 아닙니다. 예를 들어 중국어와 일본어는 일반적으로 단어 사이에 공백을 두지 않습니다. 베트남어는 음절 사이에 공백을 두기도 합니다. 여기서는 데이터셋이 (거의) 영어로 되어 있기 때문에 문제없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class EmailToWordCounterTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strip_headers=True, lower_case=True, remove_punctuation=True,\n",
    "                 replace_urls=True, replace_numbers=True, stemming=True):\n",
    "        self.strip_headers = strip_headers\n",
    "        self.lower_case = lower_case\n",
    "        self.remove_punctuation = remove_punctuation\n",
    "        self.replace_urls = replace_urls\n",
    "        self.replace_numbers = replace_numbers\n",
    "        self.stemming = stemming\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = []\n",
    "        for email in X:\n",
    "            text = email_to_text(email) or \"\"\n",
    "            if self.lower_case:\n",
    "                text = text.lower()\n",
    "            if self.replace_urls and url_extractor is not None:\n",
    "                urls = list(set(url_extractor.find_urls(text)))\n",
    "                urls.sort(key=lambda url: len(url), reverse=True)\n",
    "                for url in urls:\n",
    "                    text = text.replace(url, \" URL \")\n",
    "            if self.replace_numbers:\n",
    "                text = re.sub(r'\\d+(?:\\.\\d*(?:[eE]\\d+))?', 'NUMBER', text)\n",
    "            if self.remove_punctuation:\n",
    "                text = re.sub(r'\\W+', ' ', text, flags=re.M)\n",
    "            word_counts = Counter(text.split())\n",
    "            if self.stemming and stemmer is not None:\n",
    "                stemmed_word_counts = Counter()\n",
    "                for word, count in word_counts.items():\n",
    "                    stemmed_word = stemmer.stem(word)\n",
    "                    stemmed_word_counts[stemmed_word] += count\n",
    "                word_counts = stemmed_word_counts\n",
    "            X_transformed.append(word_counts)\n",
    "        return np.array(X_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 변환기를 몇 개의 이메일에 적용해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Counter({'chuck': 1, 'r': 1, 'stuff': 1, 'murcko': 1, 'yawn': 1, 'wrote': 1}),\n",
       "       Counter({'the': 11, 'of': 9, 'and': 8, 'by': 3, 'to': 3, 'all': 3, 'christian': 3, 'superstit': 2, 'teach': 2, 'been': 2, 'half': 2, 'jefferson': 2, 'i': 2, 'have': 2, 'one': 2, 'ha': 2, 'rogueri': 2, 'on': 2, 'jesu': 2, 'great': 1, 'found': 1, 'coercion': 1, 'they': 1, 'short': 1, 'band': 1, 'fabl': 1, 'corrupt': 1, 'known': 1, 'imprison': 1, 'url': 1, 'particular': 1, 'million': 1, 'make': 1, 'untruth': 1, 'in': 1, 'our': 1, 'paul': 1, 'featur': 1, 'thoma': 1, 'world': 1, 'william': 1, 'thi': 1, 'burnt': 1, 'men': 1, 'redeem': 1, 'support': 1, 'sinc': 1, 'over': 1, 'some': 1, 'find': 1, 'are': 1, 'letter': 1, 'a': 1, 'innoc': 1, 'becom': 1, 'what': 1, 'john': 1, 'larg': 1, 'word': 1, 'first': 1, 'histor': 1, 'led': 1, 'dupe': 1, 'earth': 1, 'perpetr': 1, 'mytholog': 1, 'import': 1, 'fine': 1, 'again': 1, 'shone': 1, 'introduct': 1, 'e': 1, 'were': 1, 'ever': 1, 'pervert': 1, 'american': 1, 'fool': 1, 'women': 1, 'absurd': 1, 'man': 1, 'quot': 1, 'do': 1, 'system': 1, 'children': 1, 'that': 1, 'effect': 1, 'other': 1, 'most': 1, 'six': 1, 'remsburg': 1, 'interest': 1, 'examin': 1, 'error': 1, 'upon': 1, 'alik': 1, 'not': 1, 'hypocrit': 1, 'tortur': 1}),\n",
       "       Counter({'url': 5, 's': 3, 'group': 3, 'to': 3, 'an': 2, 'and': 2, 'in': 2, 'we': 2, 'martin': 2, 'unsubscrib': 2, 'is': 2, 'forteana': 2, 'yahoo': 2, 'altern': 1, 'email': 1, 'hamza': 1, 'subject': 1, 'dvd': 1, 'use': 1, 'free': 1, 't': 1, 'y': 1, 'base': 1, 'be': 1, 'includ': 1, 'join': 1, 'your': 1, 'more': 1, 'yemen': 1, 'send': 1, 'rob': 1, 'unbias': 1, 'murder': 1, 'now': 1, 'for': 1, 'on': 1, 'should': 1, 'sponsor': 1, 'p': 1, 'that': 1, 'thi': 1, 'memri': 1, 'know': 1, 'don': 1, 'outright': 1, 'rather': 1, 'number': 1, 'muslim': 1, 'factual': 1, 'belief': 1, 'non': 1, 'html': 1, 'wrote': 1, 'all': 1, 'hi': 1, 'career': 1, 'of': 1, 'adamson': 1, 'how': 1, 'from': 1, 'rundown': 1})],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_few = X_train[:3]\n",
    "X_few_wordcounts = EmailToWordCounterTransformer().fit_transform(X_few)\n",
    "X_few_wordcounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제대로 작동하는 것 같네요!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 단어 카운트를 벡터로 변환해야 합니다. 이를 위해서 또 다른 변환기를 만들겠습니다. 이 변환기는 (자주 나타나는 단어 순으로 정렬된) 어휘 목록을 구축하는 `fit()` 메서드와 어휘 목록을 사용해 단어를 벡터로 바꾸는 `transform()` 메서드를 가집니다. 출력은 희소 행렬이 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "class WordCounterToVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vocabulary_size=1000):\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "    def fit(self, X, y=None):\n",
    "        total_count = Counter()\n",
    "        for word_count in X:\n",
    "            for word, count in word_count.items():\n",
    "                total_count[word] += min(count, 10)\n",
    "        most_common = total_count.most_common()[:self.vocabulary_size]\n",
    "        self.most_common_ = most_common\n",
    "        self.vocabulary_ = {word: index + 1 for index, (word, count) in enumerate(most_common)}\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        rows = []\n",
    "        cols = []\n",
    "        data = []\n",
    "        for row, word_count in enumerate(X):\n",
    "            for word, count in word_count.items():\n",
    "                rows.append(row)\n",
    "                cols.append(self.vocabulary_.get(word, 0))\n",
    "                data.append(count)\n",
    "        return csr_matrix((data, (rows, cols)), shape=(len(X), self.vocabulary_size + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x11 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 19 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_transformer = WordCounterToVectorTransformer(vocabulary_size=10)\n",
    "X_few_vectors = vocab_transformer.fit_transform(X_few_wordcounts)\n",
    "X_few_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [104,  11,   8,   9,   1,   3,   3,   1,   0,   0,   3],\n",
       "       [ 60,   0,   2,   1,   5,   3,   1,   2,   3,   3,   0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_few_vectors.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 행렬은 무엇을 의미하나요? 세 번째 행의 첫 번째 열의 65는 세 번째 이메일이 어휘 목록에 없는 단어를 65개 가지고 있다는 뜻입니다. 그 다음의 0은 어휘 목록에 있는 첫 번째 단어가 한 번도 등장하지 않는다는 뜻이고 그 다음의 1은 한 번 나타난다는 뜻입니다. 이 단어들이 무엇인지 확인하려면 어휘 목록을 보면 됩니다. 첫 번째 단어는 \"the\"이고 두 번째 단어는 \"of\"입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': 6,\n",
       " 'and': 2,\n",
       " 'christian': 10,\n",
       " 'group': 8,\n",
       " 'in': 7,\n",
       " 'of': 3,\n",
       " 's': 9,\n",
       " 'the': 1,\n",
       " 'to': 5,\n",
       " 'url': 4}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_transformer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 스팸 분류기를 훈련시킬 준비를 마쳤습니다! 전체 데이터셋을 변환시켜보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "preprocess_pipeline = Pipeline([\n",
    "    (\"email_to_wordcount\", EmailToWordCounterTransformer()),\n",
    "    (\"wordcount_to_vector\", WordCounterToVectorTransformer()),\n",
    "])\n",
    "\n",
    "X_train_transformed = preprocess_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] .................................. , score=0.98375, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.985, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................... , score=0.9925, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9870833333333334"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "log_clf = LogisticRegression(random_state=42)\n",
    "score = cross_val_score(log_clf, X_train_transformed, y_train, cv=3, verbose=3)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "98.7%가 넘네요. 첫 번째 시도치고 나쁘지 않습니다! :) 그러나 이 데이터셋은 비교적 쉬운 문제입니다. 더 어려운 데이터셋에 적용해 보면 결과가 그리 높지 않을 것입니다. 여러개의 모델을 시도해 보고 제일 좋은 것을 골라 교차 검증으로 세밀하게 튜닝해 보세요.\n",
    "\n",
    "하지만 전체 내용을 파악했으므로 여기서 멈추겠습니다. 테스트 세트에서 정밀도/재현율을 출력해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정밀도: 94.90%\n",
      "재현율: 97.89%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "X_test_transformed = preprocess_pipeline.transform(X_test)\n",
    "\n",
    "log_clf = LogisticRegression(random_state=42)\n",
    "log_clf.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred = log_clf.predict(X_test_transformed)\n",
    "\n",
    "print(\"정밀도: {:.2f}%\".format(100 * precision_score(y_test, y_pred)))\n",
    "print(\"재현율: {:.2f}%\".format(100 * recall_score(y_test, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
